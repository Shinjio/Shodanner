import requests
import json

from bs4 import BeautifulSoup

class Exploit:
    def __init__(self):
        pass

    #scrapes cvedetails.com for available exploits
    @staticmethod
    def searchCVEDetails(self, cve):

        html = requests.get("https://cvedetails.com/cve/" + cve).text
        bs = BeautifulSoup(html, "lxml")
        exploits = []
        
        metasploit = bs.find("table", {"class" : "metasploit"})
        if metasploit:
            for module in metasploit.find_all("a"):
                exploits.append(module.get("href"))

        references = bs.find(id="vulnrefstable")
        if references:
            for ref in references.find_all("a"):
                r = ref.get("href")
                if "exploit" in r:
                    exploits.append(r)

        return exploits
    @staticmethod
    def searchExploitDB(self, query):
        headers = {
            "User-Agent": "Mozilla/5.0 (X11; Linux x86_64; rv:68.0) Gecko/20100101 Firefox/68.0",
            "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8",
            "Accept-Language": "en-US,en;q=0.5",
            "Accept-Encoding": "gzip, deflate, br",
            "DNT": "1",
            "Connection": "keep-alive",
            "X-Requested-With": "XMLHttpRequest"}
        exploits = parseExploitDB(requests.get("https://www.exploit-db.com/search?verified=true&q="+query, headers=headers).text)
        exploits += parseExploitDB(requests.get("https://www.exploit-db.com/search?verified=false&q="+query, headers=headers).text)
        return exploits

def parseExploitDB(response):
    data = json.loads(response)["data"]
    l = []
    for i in data:
        href = BeautifulSoup(i["download"], features="lxml").find_all("a")[0]["href"]
        l.append("https://www.exploit-db.com"+href.replace("download","exploits"))
    return l

